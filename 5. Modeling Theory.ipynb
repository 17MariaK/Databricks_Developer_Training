{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59045008-8af6-481a-894d-9fae5a0b7ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🏛️ Data Modeling in Data Warehousing\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 What is a Data Warehouse?\n",
    "\n",
    "A **Data Warehouse (DWH)** is a centralized repository designed for reporting, analytics, and business intelligence. It integrates data from various sources and stores it in a **structured**, **historical**, and **query-optimized** format.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Key Characteristics of a DWH:\n",
    "- 💾 **Subject-oriented** (e.g., sales, finance, HR)\n",
    "- 🕓 **Time-variant** (tracks changes over time)\n",
    "- 📚 **Non-volatile** (data is read-only once loaded)\n",
    "- 🔀 **Integrated** (combines data from many sources)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Data Modeling Layers\n",
    "\n",
    "To design a Data Warehouse effectively, we use **three modeling layers**:\n",
    "\n",
    "| Layer        | Purpose                                                  | Audience                 |\n",
    "|--------------|-----------------------------------------------------------|--------------------------|\n",
    "| 🧠 **Conceptual** | High-level business view of entities and relationships   | Business stakeholders     |\n",
    "| 🧮 **Logical**    | Detailed structure: attributes, keys, relationships       | Data architects, analysts |\n",
    "| 🛠️ **Physical**   | Actual implementation: data types, indexes, partitions   | Engineers, DBAs           |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 1️⃣ Conceptual Model\n",
    "\n",
    "- Abstract view of the **business domain**\n",
    "- Identifies **main entities** and **high-level relationships**\n",
    "- No technical details (like data types or constraints)\n",
    "\n",
    "> 📌 *Example:*\n",
    "> - Entities: Customer, Product, Order\n",
    "> - Relationship: Customers place Orders\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 2️⃣ Logical Model\n",
    "\n",
    "- Refines the conceptual model into detailed **tables and columns**\n",
    "- Specifies:\n",
    "  - Primary keys\n",
    "  - Foreign keys\n",
    "  - Attribute names\n",
    "  - Normalization logic\n",
    "- Still **platform-independent**\n",
    "\n",
    "> 📌 *Example:*\n",
    "> - Table: Orders (OrderID, CustomerID, ProductID, Quantity, Date)\n",
    "> - Foreign key: Orders.CustomerID → Customers.CustomerID\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ 3️⃣ Physical Model\n",
    "\n",
    "- Translates logical model into a specific **storage implementation**\n",
    "- Defines:\n",
    "  - Data types (INT, STRING, DATE)\n",
    "  - Partitioning strategy\n",
    "  - Indexing\n",
    "  - File format (Parquet, Delta, etc.)\n",
    "  - Performance optimization (Z-Ordering, bucketing)\n",
    "\n",
    "> 📌 *Example (Delta Table)*:\n",
    "> - `CREATE TABLE orders (...) USING DELTA PARTITIONED BY (year,month)`\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 Where Do Tools Like Erwin Fit?\n",
    "\n",
    "🔧 **Modeling tools** help maintain consistency, automate documentation, and enable collaborative design.  \n",
    "They are mostly used in the **Conceptual** and **Logical** stages, but many support Physical modeling too.\n",
    "\n",
    "| Tool        | Purpose & Fit |\n",
    "|-------------|----------------|\n",
    "| **Erwin Data Modeler** | Enterprise-grade modeling and governance across conceptual, logical, and physical layers |\n",
    "| **Lucidchart / dbdiagram.io** | Great for conceptual diagrams or quick visual relationships |\n",
    "| **SQL DBM** | Cloud-based modeling with native SQL generation |\n",
    "| **dbt (Data Build Tool)** | Logical/physical model driven by code for analytics engineering, combined with transformation logic |\n",
    "| **Databricks Unity Catalog** | Tags, schemas, and lineage tracking across physical data models and assets |\n",
    "\n",
    "**Where to get Ervin?** https://onetakeda.atlassian.net/wiki/spaces/GMSGQDIME/pages/6200001174/Erwin+Data+Modeler+license\n",
    "\n",
    "> 💡 *Best practice:* Use modeling tools to track lineage, enforce standards, and automate documentation of your warehouse.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Why This Matters\n",
    "\n",
    "| Layer | Purpose |\n",
    "|-------|---------|\n",
    "| Conceptual | Align technical and business teams around key concepts |\n",
    "| Logical | Blueprint for building relationships and enforcing data integrity |\n",
    "| Physical | Ensures optimal performance and scalability for big data workloads |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5451fd-48b5-4059-8cda-7f4bb2374eab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 🌟 Star Schema vs ❄️ Snowflake Schema\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Why Does Schema Design Matter in Analytics?\n",
    "\n",
    "In Data Warehousing and Analytics, **schema design** affects:\n",
    "\n",
    "- 🔍 Query performance  \n",
    "- 🧩 Data consistency  \n",
    "- 📊 Report structure  \n",
    "- 🛠️ Maintainability  \n",
    "\n",
    "Two common schema models:\n",
    "- **Star Schema**\n",
    "- **Snowflake Schema**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbaccd87-e8b9-4f42-93e1-8b8f37f45118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 🌟 Star Schema (Denormalized)\n",
    "\n",
    "### 📌 Characteristics:\n",
    "- Central **Fact Table** (e.g., sales)  \n",
    "- Linked directly to **Dimension Tables**  \n",
    "- Dimension tables are **flattened** (denormalized)\n",
    "- Simpler and faster for queries\n",
    "\n",
    "### 🎨 Visual:\n",
    "\n",
    "---\n",
    "<pre>\n",
    "┌──────────────┐       ┌───────────┐       ┌───────┐\n",
    "│  Customers   │       │  Products │       │ Time  │\n",
    "└──────────────┘       └───────────┘       └───────┘\n",
    "         \\                 │                 /\n",
    "          \\                │                /\n",
    "           ▼               ▼               ▼\n",
    "       ┌──────────────────────────────────┐\n",
    "       │          📦 Sales (Fact)        │\n",
    "       └──────────────────────────────────┘\n",
    "</pre>\n",
    "---\n",
    "### 🧾 Example:\n",
    "\n",
    "**Fact Table: `sales_fact`**\n",
    "\n",
    "| sale_id | customer_id | product_id | date_id | amount |\n",
    "|---------|-------------|------------|---------|--------|\n",
    "| 1       | 101         | 2001       | 20230701| 300.00 |\n",
    "\n",
    "**Dimension Table: `dim_customer`**\n",
    "\n",
    "| customer_id | name   | city     | country   |\n",
    "|-------------|--------|----------|-----------|\n",
    "| 101         | Alice  | Vienna   | Austria   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdb8c814-6f43-4c86-9d64-19ebb5c8ee8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ❄️ Snowflake Schema (Normalized)\n",
    "\n",
    "### 📌 Characteristics:\n",
    "- Fact table still in center  \n",
    "- Dimensions are **normalized** into sub-tables  \n",
    "- More joins needed → queries may be slower  \n",
    "- Good for **storage efficiency**, **data quality**, and **modularity**\n",
    "\n",
    "### 🎨 Visual:\n",
    "---\n",
    "<pre>\n",
    "             ┌──────────────┐\n",
    "             │   Region     │\n",
    "             └─────▲────────┘\n",
    "                   │\n",
    "             ┌─────┴──────┐\n",
    "             │  Country   │\n",
    "             └─────▲──────┘\n",
    "                   │\n",
    "             ┌─────┴────────────┐\n",
    "             │   Customers      │\n",
    "             └────────┬─────────┘\n",
    "                      │\n",
    "     ┌────────────┐   │   ┌─────────────┐\n",
    "     │  Category  │   │   │    Time     │\n",
    "     └─────▲──────┘   │   └──────▲──────┘\n",
    "           │          │          │\n",
    "     ┌─────┴──────┐   │   ┌──────┴────────────┐\n",
    "     │  Products  │───┼──▶│ 📦 Sales (Fact)   │\n",
    "     └────────────┘       └───────────────────┘  \n",
    "</pre>\n",
    "---\n",
    "\n",
    "### 🧾 Example:\n",
    "\n",
    "**Dimension Breakdown:**\n",
    "\n",
    "- `dim_customer` → has `country_id`\n",
    "- `dim_country` → has `region_id`\n",
    "\n",
    "**dim_customer**\n",
    "\n",
    "| customer_id | name   | country_id |\n",
    "|-------------|--------|------------|\n",
    "| 101         | Alice  | 10         |\n",
    "\n",
    "**dim_country**\n",
    "\n",
    "| country_id | country | region_id |\n",
    "|------------|---------|-----------|\n",
    "| 10         | Austria | 1         |\n",
    "\n",
    "**dim_region**\n",
    "\n",
    "| region_id | region      |\n",
    "|-----------|-------------|\n",
    "| 1         | Europe      |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Normalization Theory Recap\n",
    "\n",
    "| Normal Form | Goal                       | Example Fix                        |\n",
    "|-------------|----------------------------|-------------------------------------|\n",
    "| 1NF         | Atomic values only         | Split comma-separated fields       |\n",
    "| 2NF         | Remove partial dependencies| Separate repeated group values     |\n",
    "| 3NF         | Remove transitive dep.     | Separate city from customer table  |\n",
    "\n",
    "> 🧠 *Snowflake schema uses normalization up to 3NF to reduce redundancy and enforce integrity.*\n",
    "\n",
    "---\n",
    "\n",
    "## ⚖️ Comparison Table\n",
    "\n",
    "| Feature              | ⭐ Star Schema     | ❄️ Snowflake Schema |\n",
    "|----------------------|-------------------|---------------------|\n",
    "| Joins Required       | Fewer             | More                |\n",
    "| Performance (Queries)| Faster            | Slower (more joins) |\n",
    "| Storage Usage        | Higher            | Lower               |\n",
    "| Maintenance          | Easier            | More complex        |\n",
    "| Normalization        | Denormalized      | Normalized (3NF)    |\n",
    "| Use Case             | Reporting, BI     | Complex ETL, compliance |\n",
    "\n",
    "---\n",
    "\n",
    "## 🏁 Summary\n",
    "\n",
    "- **Use Star Schema** when performance is key and simplicity helps reporting teams  \n",
    "- **Use Snowflake Schema** when storage optimization and relational consistency matter  \n",
    "\n",
    "In practice, many modern data platforms (including Databricks) support **hybrid approaches**, blending star-style dimensions with normalized lookups.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d52710e-5d71-4e5c-b88c-ad463ed1a938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 🎯 Granularity in Data Modeling\n",
    "\n",
    "---\n",
    "\n",
    "### 🤔 What is Granularity?\n",
    "\n",
    "Granularity defines the **level of detail** or **depth of data** stored in a fact table within a data warehouse.\n",
    "\n",
    "- It answers the question:  \n",
    "  *\"What is the most atomic unit of data captured?\"*\n",
    "\n",
    "- The **granularity** determines how **detailed** or **aggregated** your data is.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚡ Why is Granularity Important?\n",
    "\n",
    "- **Too fine granularity**:  \n",
    "  - ❗ Can cause **large storage** needs and **slow queries**.  \n",
    "  - Example: Storing every individual click on a website.\n",
    "\n",
    "- **Too coarse granularity**:  \n",
    "  - ⚠️ May **lose important details** needed for analysis.  \n",
    "  - Example: Aggregating daily sales only at the country level, missing store-level insights.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Examples of Granularity Levels in Sales Data\n",
    "\n",
    "| Granularity Level                 | Description                                   | Example Fact Record                          |\n",
    "|---------------------------------|-----------------------------------------------|---------------------------------------------|\n",
    "| **Transaction-level**            | Each individual sale or event                  | 🛒 Single product sold to a customer at a time |\n",
    "| **Daily store-level**            | Aggregated sales per store per day             | 🏬 Total daily sales at Store A on July 1       |\n",
    "| **Monthly region-level**         | Aggregated monthly sales per region             | 🌍 Total sales in the North region in July      |\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 Key Considerations\n",
    "\n",
    "- Granularity **should be consistent** across the fact table.  \n",
    "- A **well-defined granularity** enables better joins with dimension tables and easier maintenance.  \n",
    "- The grain must be clear to **avoid mixing data levels** which causes inaccurate analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔗 How Granularity Links to Dimensions\n",
    "\n",
    "The grain of a fact table usually relates to the combination of **foreign keys** linking to dimension tables:\n",
    "\n",
    "- For example, if granularity is daily sales per store per product, then dimension keys could be:  \n",
    "  `date_key`, `store_key`, `product_key`\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Summary\n",
    "\n",
    "> **Defining the correct granularity is foundational for a performant, flexible, and useful data warehouse.**  \n",
    "> It directly impacts storage size, query performance, and the quality of business insights.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee96989-f5b4-44ab-826b-31287e7d8b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🔗 Relationships in Data Modeling\n",
    "\n",
    "---\n",
    "\n",
    "### 1️⃣ One-to-One (1:1) Relationship\n",
    "\n",
    "- Each record in **Table A** corresponds to **exactly one** record in **Table B**, and vice versa.\n",
    "- Rare in data warehouses but useful for splitting tables for security or performance reasons.\n",
    "\n",
    "**Example:**  \n",
    "- Employee ↔ Employee Details (e.g., sensitive info stored separately)\n",
    "\n",
    "| Employee_ID | Name    |  \n",
    "|-------------|---------|  \n",
    "| 1           | Alice   |  \n",
    "\n",
    "| Employee_ID | Social Security Number |  \n",
    "|-------------|-----------------------|  \n",
    "| 1           | 123-45-6789           |  \n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ One-to-Many (1:N) Relationship\n",
    "\n",
    "- One record in **Table A** can be linked to **many records** in **Table B**.\n",
    "- This is the most common relationship in data warehouses.\n",
    "\n",
    "**Example:**  \n",
    "- Customer(dim) → Orders(fact)  \n",
    "- A single customer can have multiple orders.\n",
    "\n",
    "| Customer_ID | Name      |  \n",
    "|-------------|-----------|  \n",
    "| 1001        | John Doe  |  \n",
    "\n",
    "| Order_ID | Customer_ID | Order_Date |  \n",
    "|----------|-------------|------------|  \n",
    "| 5001     | 1001        | 2025-07-01 |  \n",
    "| 5002     | 1001        | 2025-07-03 |  \n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ Many-to-Many (M:N) Relationship\n",
    "\n",
    "- Many records in **Table A** can relate to many records in **Table B**.\n",
    "- Usually modeled by introducing a **junction (bridge) table**.\n",
    "\n",
    "**Example:**  \n",
    "- Students ↔ Courses  \n",
    "- A student can enroll in many courses, and a course can have many students.\n",
    "\n",
    "| Student_ID | Name      |  \n",
    "|------------|-----------|  \n",
    "| 1          | Alice     |  \n",
    "\n",
    "| Course_ID | Course_Name |  \n",
    "|-----------|-------------|  \n",
    "| 101       | Math        |  \n",
    "\n",
    "| Enrollment (Junction Table) |  \n",
    "|-----------------------------|  \n",
    "| Student_ID | Course_ID      |  \n",
    "| 1          | 101            |  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 Summary of Relationships\n",
    "\n",
    "| Relationship   | Description                     | Data Modeling Example          |\n",
    "|----------------|--------------------------------|-------------------------------|\n",
    "| One-to-One     | 1 record ↔ 1 record            | Employee ↔ Employee Details    |\n",
    "| One-to-Many    | 1 record ↔ Many records        | Customer → Orders              |\n",
    "| Many-to-Many   | Many records ↔ Many records    | Students ↔ Courses (via Enrollment) |\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Pro Tip\n",
    "\n",
    "- **Foreign keys** implement these relationships physically.\n",
    "- Properly defining relationships ensures **data integrity** and **efficient joins**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2d24297-e8c8-44f2-b43f-104d11faa857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ⚙️ Data Load Strategies in Data Warehousing\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Append-Only Load\n",
    "\n",
    "- New data rows are **only appended** to the target table.\n",
    "- No rows are updated or deleted.\n",
    "- Often combined with a **marker column** to indicate the type of operation:\n",
    "  - `'I'` = Insert\n",
    "  - `'U'` = Update\n",
    "  - `'D'` = Delete (soft delete marker)\n",
    "\n",
    "**Use case:**  \n",
    "Audit logs, event streams where history is preserved.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Truncate / Full Load\n",
    "\n",
    "- Target table is **completely emptied (truncated)** before loading fresh data.\n",
    "- Simple but expensive and usually only suitable for small datasets or staging layers.\n",
    "\n",
    "**Use case:**  \n",
    "Initial data load or when source data refreshes completely.\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Slowly Changing Dimension Type 1 (SCD1)\n",
    "\n",
    "- Overwrites existing records with new data.\n",
    "- No history is kept.\n",
    "- Simple and efficient for attributes where history is not important.\n",
    "\n",
    "**Example:**  \n",
    "Updating a customer’s address to the latest one.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Custom SCD1,5 with Active Flag (Custom Approach)\n",
    "\n",
    "- Similar to SCD1 but **no deletes**.\n",
    "- Instead of deleting, update an **active flag** from `'Y'` → `'N'`.\n",
    "- Keeps data \"soft deleted\" for audit and historical reference.\n",
    "- Only one record is marked active (`'Y'`) per business key at a time.\n",
    "\n",
    "**Benefits:**  \n",
    "- Easy to implement and query.\n",
    "- Supports some history without complex SCD2 mechanics.\n",
    "- Avoids physical deletes improving data safety.\n",
    "\n",
    "**Example schema snippet:**\n",
    "\n",
    "| customer_id | name     | address      | active_flag | last_updated          |\n",
    "|-------------|----------|--------------|-------------|-----------------------|\n",
    "| 1001        | John Doe | 123 Main St  | Y           | 2025-07-22 12:00:00   |\n",
    "| 1001        | John Doe | 456 Oak Ave  | N           | 2025-01-15 08:30:00   |\n",
    "---\n",
    "\n",
    "## 5️⃣ Slowly Changing Dimension Type 2 (SCD2)\n",
    "\n",
    "- Keeps full history of changes by creating **new records** for changes.\n",
    "- Adds columns like `effective_date`, `end_date`, and `current_flag` to track active record.\n",
    "- Supports historical analysis.\n",
    "\n",
    "**Example:**  \n",
    "Tracking changes in customer’s health plan status over time.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 Summary Table of Load Strategies\n",
    "\n",
    "| Strategy                 | History Preserved? | Typical Use Case                 | Notes                              |\n",
    "|--------------------------|--------------------|--------------------------------|----------------------------------|\n",
    "| Append-Only              | No                 | Audit logs, event streams       | Marker column tracks operation   |\n",
    "| Truncate / Full Load     | No                 | Initial loads, small datasets   | Expensive for big tables         |\n",
    "| SCD Type 1               | No                 | Overwrite attributes            | Simple, no history               |\n",
    "| SCD Type 1,5  | Partial          | Soft deletes, light history     | No physical deletes, simple logic|\n",
    "| SCD Type 2               | Yes                | Full history tracking           | Complex, multiple records per key|\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Important in our pipelines\n",
    "\n",
    "- We typically use **Custom SCD1 with Active Flag** for easy auditability and soft deletes.\n",
    "- Delta Live Tables (DLT) and Spark SQL `MERGE` statements make implementing these patterns efficient and clear.\n",
    "- Adding **row keys, audit columns, and standardization** functions ensures clean, consistent data loads.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9077e03b-460f-4e1c-aa43-fe59163b0a91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🔁 Delta Live Tables (DLT) & Change Data Capture (CDC)\n",
    "\n",
    "Delta Live Tables offers a powerful and simplified way to process **Change Data Capture (CDC)** using **declarative syntax**, removing the complexity of manual `MERGE` statements.\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Why This Matters\n",
    "\n",
    "Traditional CDC implementations often rely on complex `MERGE` statements that:\n",
    "- Fail with out-of-order data\n",
    "- Struggle with deletes/truncates\n",
    "- Are hard to scale or maintain\n",
    "\n",
    "With **DLT’s built-in CDC capabilities**, you can now declaratively apply changes, deduplicate, sequence, and even handle slowly changing dimensions (SCDs).\n",
    "\n",
    "### ✅ `AUTO CDC INTO` (SQL)\n",
    "\n",
    "```sql\n",
    "CREATE FLOW cdc_pipeline AS AUTO CDC INTO target_table\n",
    "FROM source_table\n",
    "KEYS (business_key)\n",
    "APPLY AS DELETE WHEN operation = 'DELETE'\n",
    "SEQUENCE BY event_ts\n",
    "STORED AS SCD TYPE 2\n",
    "TRACK HISTORY ON *;\n",
    "\n",
    "\n",
    "```\n",
    "### ✅ `AUTO CDC INTO` (PYTHON)\n",
    "```import dlt\n",
    "\n",
    "dlt.create_auto_cdc_flow(\n",
    "    target=\"prod.sales_orders\",\n",
    "    source=\"raw.cdc_orders\",\n",
    "    keys=[\"order_id\"],\n",
    "    sequence_by=\"event_ts\",\n",
    "    stored_as_scd_type=\"SCD2\",\n",
    "    apply_as_deletes=\"operation = 'DELETE'\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "**For more detailed information pelase check documentation:** https://docs.databricks.com/aws/en/dlt/cdc\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5. Modeling Theory",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
